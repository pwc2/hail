{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pc_relate_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env HAIL_QUERY_BACKEND=local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import hail as hl\n",
    "# hl.utils.get_1kg('tmp/')\n",
    "mt = hl.read_matrix_table('tmp/1kg.mt')\n",
    "mt.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute results from current implementation located at `hail/hail/python/hail/methods/relatedness/pc_relate.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "pc_rel = hl.pc_relate(mt.GT, min_individual_maf=0.01, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps from current implementation that we can just reuse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get PC scores\n",
    "from hail.methods.pca import hwe_normalized_pca\n",
    "_, scores, _ = hwe_normalized_pca(mt.GT, k=10, compute_loadings=False)\n",
    "scores_expr = scores[mt.col_key].scores\n",
    "scores_table = mt.select_cols(__scores=scores_expr)\\\n",
    "    .key_cols_by().select_cols('__scores').cols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Check for missing scores, create entries for g matrix\n",
    "import hail.expr.aggregators as agg\n",
    "n_missing = scores_table.aggregate(agg.count_where(hl.is_missing(scores_table.__scores)))\n",
    "if n_missing > 0:\n",
    "    raise ValueError(f'Found {n_missing} columns with missing scores array.')\n",
    "mt = mt.select_entries(__gt=mt.GT.n_alt_alleles()).unfilter_entries()\n",
    "mt = mt.annotate_rows(__mean_gt=agg.mean(mt.__gt))\n",
    "mean_imputed_gt = hl.or_else(hl.float64(mt.__gt), mt.__mean_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get PCs and g matrix\n",
    "from hail.linalg import BlockMatrix\n",
    "block_size = BlockMatrix.default_block_size()\n",
    "g_bm = BlockMatrix.from_entry_expr(mean_imputed_gt, block_size=block_size).persist()\n",
    "pcs = scores_table.collect(_localize=False).map(lambda x: x.__scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the current implementation calls:\n",
    "\n",
    "```\n",
    "ht = Table(ir.BlockMatrixToTableApply(g._bmir, pcs._ir, {\n",
    "    'name': 'PCRelate',\n",
    "    'maf': min_individual_maf,\n",
    "    'blockSize': block_size,\n",
    "    'minKinship': min_kinship,\n",
    "    'statistics': {'kin': 0, 'kin2': 1, 'kin20': 2, 'all': 3}[statistics]\n",
    "}))\n",
    "```\n",
    "\n",
    "So we want to replace the Scala code at `hail/hail/src/main/scala/is/hail/methods/PCRelate.scala` with Python that can run on the query backend.\n",
    "\n",
    "Below we'll work out a new implementation, will just refer to it as `pc_relate_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat array of ones (intercept) with PCs, do QR\n",
    "pcs_nd = hl.nd.array(pcs)\n",
    "v_nd = hl.nd.concatenate([hl.nd.ones((pcs_nd.shape[0], 1)), pcs_nd], axis=1)\n",
    "q_nd, r_nd = hl.nd.qr(v_nd, mode='reduced')\n",
    "rinv_qt_nd = hl.nd.inv(r_nd) @ q_nd.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dims\n",
    "nd_shapes = {\n",
    "    'v': hl.eval(v_nd.shape),\n",
    "    'q': hl.eval(q_nd.shape),\n",
    "    'r': hl.eval(r_nd.shape),\n",
    "    'rinv @ qT': hl.eval(rinv_qt_nd.shape)\n",
    "}\n",
    "print(nd_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert inv(r) @ q.T to bm for computing beta\n",
    "rinv_qt_bm = BlockMatrix.from_numpy(hl.eval(rinv_qt_nd))\n",
    "beta_bm = (rinv_qt_bm @ g_bm.T).persist()\n",
    "\n",
    "# Convert v to bm for computing mu\n",
    "v_bm = BlockMatrix.from_numpy(hl.eval(v_nd))\n",
    "mu_bm = (0.5 * (v_bm @ beta_bm).T).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dims again\n",
    "bm_shapes = {\n",
    "    'rinv @ qT': hl.eval(rinv_qt_bm.shape),\n",
    "    'beta': hl.eval(beta_bm.shape),\n",
    "    'v': hl.eval(v_bm.shape),\n",
    "    'mu': hl.eval(mu_bm.shape),\n",
    "    'g': hl.eval(g_bm.shape)\n",
    "}\n",
    "print(bm_shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a few methods to use below to check the entries in mu and g matrices, as well as compute Gram matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_individual_maf = 0.01\n",
    "\n",
    "def _bad_mu(mu, maf):\n",
    "    return (mu <= maf) | (mu >= (1.0 - maf)) | (mu <= 0.0) | (mu >= 1.0)\n",
    "\n",
    "def _bad_gt(gt):\n",
    "    return (gt != hl.float64(0)) & (gt != hl.float64(1)) & (gt != hl.float64(2))\n",
    "\n",
    "def _gram(M):\n",
    "    return M.T @ M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workaround without using Block Matrix `map` function.\n",
    "\n",
    "Convert Block Matrices for g, mu to matrix tables to check bad values and get centered AFs. \n",
    "\n",
    "Annotate entries for mu^2, (1-mu)^2, variance, std_dev, centered_af dealing with bad values. \n",
    "\n",
    "Convert needed matrix table entries back to Block Matrices and compute estimate for phi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define NaN to use instead of missing values, otherwise cannot go back to block matrix\n",
    "nan = hl.literal(0) / 0\n",
    "\n",
    "g_mt = g_bm.to_matrix_table_row_major()\n",
    "g_mt = g_mt.annotate_entries(g = hl.if_else(_bad_gt(g_mt.element), nan, g_mt.element)).drop(\"element\")\n",
    "\n",
    "pre_mu_mt = mu_bm.to_matrix_table_row_major()\n",
    "pre_mu_mt = pre_mu_mt.annotate_entries(pre_mu = hl.if_else(_bad_mu(pre_mu_mt.element, min_individual_maf), \n",
    "                                                           nan, \n",
    "                                                           pre_mu_mt.element)).drop(\"element\")\n",
    "\n",
    "\n",
    "# Use bm_mt to store entries for g, pre_mu, mu, var, and centered_af\n",
    "bm_mt = g_mt.annotate_entries(pre_mu = pre_mu_mt[g_mt.row_idx, g_mt.col_idx].pre_mu)\n",
    "bm_mt = bm_mt.annotate_entries(mu = hl.if_else(hl.is_nan(bm_mt.g) | hl.is_nan(bm_mt.pre_mu),\n",
    "                                             nan,\n",
    "                                             bm_mt.pre_mu))\n",
    "\n",
    "bm_mt = bm_mt.annotate_entries(mu2 = hl.if_else(hl.is_nan(bm_mt.mu), \n",
    "                                                0.0, \n",
    "                                                bm_mt.mu ** 2), \n",
    "                               one_minus_mu2 = hl.if_else(hl.is_nan(bm_mt.mu), \n",
    "                                                          0.0, \n",
    "                                                          (1.0 - bm_mt.mu) ** 2),\n",
    "                               variance = hl.if_else(hl.is_nan(bm_mt.mu),\n",
    "                                                     0.0,\n",
    "                                                     (bm_mt.mu * (1.0 - bm_mt.mu))), \n",
    "                               centered_af = hl.if_else(hl.is_nan(bm_mt.mu), \n",
    "                                                        0.0, \n",
    "                                                        (bm_mt.g / 2) - bm_mt.mu))\n",
    "bm_mt = bm_mt.annotate_entries(std_dev = hl.sqrt(bm_mt.variance))\n",
    "bm_mt.show(n_cols=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute our estimate of phi, and compare to the existing pc_relate implementation in Hail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centered_af_bm = BlockMatrix.from_entry_expr(bm_mt.centered_af)\n",
    "std_dev_bm = BlockMatrix.from_entry_expr(bm_mt.std_dev)\n",
    "\n",
    "phi_bm = (_gram(centered_af_bm) / _gram(std_dev_bm)).persist()\n",
    "phi_bm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute values needed to estimate $\\widehat{k_{ij}^{(0)}}$, $\\widehat{k_{ij}^{(1)}}$, and $\\widehat{k_{ij}^{(2)}}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table w/ entries from phi_bm, will use to store k0, k1, k2 estimates\n",
    "results_ht = phi_bm.entries().rename({\"entry\": \"kin\"})\n",
    "results_ht = results_ht.annotate(k0 = hl.missing(hl.tfloat64),\n",
    "                                 k1 = hl.missing(hl.tfloat64), \n",
    "                                 k2 = hl.missing(hl.tfloat64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create table w/ self-kinship (phi_ii) values\n",
    "phi_ii_ht = phi_bm.diagonal().entries().key_by(\"j\").drop(\"i\").rename({\"j\": \"idx\", \"entry\": \"phi_ii\"})\n",
    "\n",
    "# Annotate cols of bm_mt w/ self-kinship (phi_ii) and inbreeding coef (f_i)\n",
    "bm_mt = bm_mt.annotate_cols(phi_ii = phi_ii_ht[bm_mt.col_idx].phi_ii, \n",
    "                            f_i = (2.0 * phi_ii_ht[bm_mt.col_idx].phi_ii) - 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create entries for dominance encoding of genotype matrix (gd and normalized_gd)\n",
    "bm_mt = bm_mt.annotate_entries(gd = hl.case()\n",
    "                               .when(hl.is_nan(bm_mt.mu), 0.0)\n",
    "                               .when(bm_mt.g == 0.0, bm_mt.mu)\n",
    "                               .when(bm_mt.g == 1.0, 0.0)\n",
    "                               .when(bm_mt.g == 2.0, 1 - bm_mt.mu)\n",
    "                               .default(nan))\n",
    "bm_mt = bm_mt.annotate_entries(normalized_gd = bm_mt.gd - bm_mt.variance * (1 + bm_mt.f_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute $\\widehat{k_{ij}^{(2)}}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_gd_bm = BlockMatrix.from_entry_expr(bm_mt.normalized_gd)\n",
    "variance_bm = BlockMatrix.from_entry_expr(bm_mt.variance)\n",
    "k2_bm = _gram(normalized_gd_bm) / _gram(variance_bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_ht = results_ht.annotate(k2 = k2_bm.entries()[results_ht.i, results_ht.j].entry)\n",
    "results_ht.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can compute $\\widehat{k_{ij}^{(0)}}$, and then $\\widehat{k_{ij}^{(1)}}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _AtB_plus_BtA(A, B):\n",
    "    temp = (A.T @ B).persist()\n",
    "    return temp + temp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bm_mt = bm_mt.annotate_entries(hom_alt = hl.if_else((hl.is_nan(bm_mt.mu) | (bm_mt.g != 2.0)),\n",
    "                                                    0.0,\n",
    "                                                    1.0), \n",
    "                               hom_ref = hl.if_else((hl.is_nan(bm_mt.mu) | (bm_mt.g != 0.0)), \n",
    "                                                    0.0, \n",
    "                                                    1.0))\n",
    "hom_alt_bm = BlockMatrix.from_entry_expr(bm_mt.hom_alt)\n",
    "hom_ref_bm = BlockMatrix.from_entry_expr(bm_mt.hom_ref)\n",
    "ibs0_bm = _AtB_plus_BtA(hom_alt_bm, hom_ref_bm)\n",
    "\n",
    "mu2_bm = BlockMatrix.from_entry_expr(bm_mt.mu2)\n",
    "one_minus_mu2_bm = BlockMatrix.from_entry_expr(bm_mt.one_minus_mu2)\n",
    "k0_bm = (ibs0_bm / _AtB_plus_BtA(mu2_bm, one_minus_mu2_bm)).persist()\n",
    "\n",
    "results_ht = results_ht.annotate(k0 = k0_bm.entries()[results_ht.i, results_ht.j].entry)\n",
    "results_ht.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_k0_cutoff = 2.0**(-5/2)\n",
    "results_ht = results_ht.annotate(k0 = hl.if_else(results_ht.kin <= _k0_cutoff, \n",
    "                                                 (1.0 - (4.0 * results_ht.kin) + results_ht.k2),\n",
    "                                                 results_ht.k0))\n",
    "\n",
    "results_ht = results_ht.annotate(k1 = 1 - results_ht.k2 - results_ht.k0)\n",
    "results_ht.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_keys = hl.literal(mt.select_cols().key_cols_by().cols().collect(), \n",
    "                      dtype=hl.tarray(mt.col_key.dtype))\n",
    "\n",
    "pc_rel_2 = results_ht.key_by(i=col_keys[hl.int32(results_ht.i)], \n",
    "                             j=col_keys[hl.int32(results_ht.j)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare_ht = pc_rel.join(pc_rel_2)\n",
    "compare_ht.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Without self_kinship count should match pc_relate count\n",
    "pc_rel_2 = pc_rel_2.filter(pc_rel_2.i == pc_rel_2.j, keep=False)\n",
    "print(pc_rel_2.count() / 2)\n",
    "print(pc_rel_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
